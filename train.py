import os
import argparse
import time
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
from torch.amp import GradScaler, autocast  # ç”¨äºæ··åˆç²¾åº¦è®­ç»ƒ
import torch.distributed as dist  # åˆ†å¸ƒå¼è®­ç»ƒ
from torch.nn.parallel import DistributedDataParallel as DDP  # åˆ†å¸ƒå¼æ•°æ®å¹¶è¡Œ
from torch.utils.data.distributed import DistributedSampler  # åˆ†å¸ƒå¼é‡‡æ ·å™¨
from torch.utils.tensorboard import SummaryWriter  # TensorBoardå¯è§†åŒ–
from tqdm import tqdm  # è¿›åº¦æ¡

# å¯¼å…¥è‡ªå®šä¹‰æ¨¡å—
from models.unet3d import UNet3D  # 3D U-Netæ¨¡å‹
from utils.data_utils import get_data_loaders  # æ•°æ®åŠ è½½å·¥å…·
from utils.metrics import multiclass_dice_coefficient, multiclass_hausdorff_distance  # è¯„ä¼°æŒ‡æ ‡
from utils.visualization import save_prediction_visualization  # å¯è§†åŒ–å·¥å…·


def parse_args():
    """è§£æå‘½ä»¤è¡Œå‚æ•°
    
    å®šä¹‰å¹¶è§£æè®­ç»ƒè„šæœ¬çš„å‘½ä»¤è¡Œå‚æ•°ï¼ŒåŒ…æ‹¬æ•°æ®è·¯å¾„ã€æ¨¡å‹é…ç½®ã€è®­ç»ƒå‚æ•°ç­‰
    
    è¿”å›:
        argparse.Namespace: è§£æåçš„å‚æ•°å¯¹è±¡
    """
    parser = argparse.ArgumentParser(description='Train 3D U-Net on BraTS2021 dataset')
    
    # æ•°æ®å‚æ•°
    parser.add_argument('--data_dir', type=str, default='./data/BraTS2021_Training_Data',
                        help='BraTS2021æ•°æ®é›†æ ¹ç›®å½•')
    parser.add_argument('--output_dir', type=str, default='./output',
                        help='è¾“å‡ºç›®å½•ï¼Œç”¨äºä¿å­˜æ¨¡å‹å’Œæ—¥å¿—')
    
    # æ¨¡å‹å‚æ•°
    parser.add_argument('--in_channels', type=int, default=4,
                        help='è¾“å…¥é€šé“æ•°ï¼Œå¯¹åº”å››ç§æ¨¡æ€(T1ã€T1ceã€T2ã€FLAIR)')
    parser.add_argument('--out_channels', type=int, default=4,
                        help='è¾“å‡ºé€šé“æ•°ï¼Œå¯¹åº”åˆ†å‰²ç±»åˆ«æ•°(èƒŒæ™¯ã€åæ­»æ ¸å¿ƒã€æ°´è‚¿ã€å¢å¼ºè‚¿ç˜¤)')
    parser.add_argument('--features', type=int, nargs='+', default=[16, 32, 64, 128, 256],
                        help='æ¯å±‚çš„ç‰¹å¾å›¾æ•°é‡ï¼Œä»æµ…å±‚åˆ°æ·±å±‚')
    parser.add_argument('--deep_supervision', action='store_true',
                        help='æ˜¯å¦ä½¿ç”¨æ·±åº¦ç›‘ç£ï¼Œä»å¤šä¸ªæ·±åº¦å±‚çº§è¾“å‡ºé¢„æµ‹ç»“æœ')
    parser.add_argument('--residual', action='store_true', default=True,
                        help='æ˜¯å¦ä½¿ç”¨æ®‹å·®è¿æ¥ï¼Œæœ‰åŠ©äºè®­ç»ƒæ›´æ·±çš„ç½‘ç»œ')
    
    # è®­ç»ƒå‚æ•°
    parser.add_argument('--batch_size', type=int, default=1,
                        help='æ‰¹é‡å¤§å°ï¼Œå—GPUå†…å­˜é™åˆ¶')
    parser.add_argument('--epochs', type=int, default=100,
                        help='è®­ç»ƒè½®æ•°ï¼Œæ€»è®­ç»ƒæ¬¡æ•°')
    parser.add_argument('--lr', type=float, default=1e-4,
                        help='åˆå§‹å­¦ä¹ ç‡ï¼ŒAdamä¼˜åŒ–å™¨çš„å­¦ä¹ ç‡')
    parser.add_argument('--weight_decay', type=float, default=1e-5,
                        help='æƒé‡è¡°å‡ï¼Œç”¨äºL2æ­£åˆ™åŒ–')
    parser.add_argument('--patience', type=int, default=10,
                        help='æ—©åœè€å¿ƒå€¼ï¼ŒéªŒè¯é›†æ€§èƒ½ä¸å†æå‡çš„æœ€å¤§è½®æ•°')
    parser.add_argument('--target_shape', type=int, nargs='+', default=[128, 128, 128],
                        help='ç›®æ ‡ä½“ç§¯å½¢çŠ¶ï¼Œç”¨äºé‡é‡‡æ ·MRIä½“ç§¯')
    
    # åˆ†å¸ƒå¼è®­ç»ƒå‚æ•°
    parser.add_argument('--distributed', action='store_true',
                        help='æ˜¯å¦ä½¿ç”¨åˆ†å¸ƒå¼è®­ç»ƒï¼Œå¤šGPUè®­ç»ƒ')
    parser.add_argument('--local_rank', type=int, default=-1,
                        help='åˆ†å¸ƒå¼è®­ç»ƒçš„æœ¬åœ°æ’åï¼Œç”±torch.distributed.launchè®¾ç½®')
    parser.add_argument('--num_workers', type=int, default=0,
                        help='æ•°æ®åŠ è½½å™¨çš„å·¥ä½œè¿›ç¨‹æ•°ï¼Œç”¨äºå¹¶è¡Œæ•°æ®åŠ è½½')
    
    # æ··åˆç²¾åº¦è®­ç»ƒ
    parser.add_argument('--amp', action='store_true', default=True,
                        help='æ˜¯å¦ä½¿ç”¨æ··åˆç²¾åº¦è®­ç»ƒï¼Œå¯åŠ é€Ÿè®­ç»ƒå¹¶å‡å°‘å†…å­˜ä½¿ç”¨')
    
    # å¯è§†åŒ–å‚æ•°
    parser.add_argument('--vis_freq', type=int, default=10,
                        help='å¯è§†åŒ–é¢‘ç‡ï¼ˆæ¯nä¸ªepochä¿å­˜ä¸€æ¬¡å¯è§†åŒ–ç»“æœï¼‰')
    
    return parser.parse_args()


def setup_distributed(args):
    """è®¾ç½®åˆ†å¸ƒå¼è®­ç»ƒç¯å¢ƒ
    
    åˆå§‹åŒ–åˆ†å¸ƒå¼è®­ç»ƒç¯å¢ƒï¼Œè®¾ç½®å½“å‰è®¾å¤‡å’Œè¿›ç¨‹ç»„
    
    å‚æ•°:
        args: å‘½ä»¤è¡Œå‚æ•°å¯¹è±¡ï¼ŒåŒ…å«åˆ†å¸ƒå¼è®­ç»ƒç›¸å…³é…ç½®
    """
    if args.distributed:
        # è®¾ç½®å½“å‰è®¾å¤‡
        torch.cuda.set_device(args.local_rank)
        # åˆå§‹åŒ–è¿›ç¨‹ç»„ï¼Œä½¿ç”¨NCCLåç«¯ï¼ˆé€‚ç”¨äºGPUï¼‰
        dist.init_process_group(backend='nccl')
        # è·å–æ€»è¿›ç¨‹æ•°å’Œå½“å‰è¿›ç¨‹æ’å
        args.world_size = dist.get_world_size()
        args.rank = dist.get_rank()
    else:
        # éåˆ†å¸ƒå¼è®­ç»ƒæ—¶ï¼Œè®¾ç½®ä¸ºå•è¿›ç¨‹
        args.world_size = 1
        args.rank = 0


def get_model(args):
    """åˆ›å»ºæ¨¡å‹å®ä¾‹
    
    æ ¹æ®å‚æ•°åˆ›å»º3D U-Netæ¨¡å‹å®ä¾‹
    
    å‚æ•°:
        args: å‘½ä»¤è¡Œå‚æ•°å¯¹è±¡ï¼ŒåŒ…å«æ¨¡å‹é…ç½®
        
    è¿”å›:
        UNet3D: åˆ›å»ºçš„æ¨¡å‹å®ä¾‹
    """
    model = UNet3D(
        in_channels=args.in_channels,  # è¾“å…¥é€šé“æ•°ï¼ˆå››ç§æ¨¡æ€ï¼‰
        out_channels=args.out_channels,  # è¾“å‡ºé€šé“æ•°ï¼ˆåˆ†å‰²ç±»åˆ«æ•°ï¼‰
        features=args.features,  # æ¯å±‚ç‰¹å¾å›¾æ•°é‡
        deep_supervision=args.deep_supervision,  # æ˜¯å¦ä½¿ç”¨æ·±åº¦ç›‘ç£
        residual=args.residual  # æ˜¯å¦ä½¿ç”¨æ®‹å·®è¿æ¥
    )
    
    return model


def get_loss_function():
    """æ„å»ºç»„åˆæŸå¤±å‡½æ•°
    
    åŒ»å­¦å›¾åƒåˆ†å‰²ä»»åŠ¡ä¸­ï¼Œå•ä¸€æŸå¤±å‡½æ•°å¾€å¾€æ— æ³•å¾ˆå¥½åœ°å¤„ç†ç±»åˆ«ä¸å¹³è¡¡å’Œè¾¹ç•Œç²¾ç¡®æ€§é—®é¢˜ã€‚
    æœ¬å‡½æ•°æ„å»ºäº†ä¸€ä¸ªç»„åˆæŸå¤±å‡½æ•°ï¼Œç»“åˆäº†äº¤å‰ç†µæŸå¤±å’ŒDiceæŸå¤±çš„ä¼˜åŠ¿ï¼š
    
    1. äº¤å‰ç†µæŸå¤±ï¼ˆCross-Entropy Lossï¼‰ï¼š
       - ä¼˜åŠ¿ï¼šè®­ç»ƒç¨³å®šï¼Œæ”¶æ•›å¿«ï¼Œå¯¹ç±»åˆ«ä¸å¹³è¡¡æœ‰ä¸€å®šé²æ£’æ€§
       - åŠ£åŠ¿ï¼šä¸»è¦å…³æ³¨åƒç´ çº§åˆ†ç±»ï¼Œå¯¹åˆ†å‰²åŒºåŸŸçš„æ•´ä½“æ€§è€ƒè™‘ä¸è¶³
    
    2. DiceæŸå¤±ï¼ˆDice Lossï¼‰ï¼š
       - ä¼˜åŠ¿ï¼šç›´æ¥ä¼˜åŒ–Diceç³»æ•°ï¼Œå…³æ³¨åˆ†å‰²åŒºåŸŸçš„é‡å åº¦ï¼Œå¯¹å°ç›®æ ‡å‹å¥½
       - åŠ£åŠ¿ï¼šè®­ç»ƒåˆæœŸå¯èƒ½ä¸ç¨³å®šï¼Œæ¢¯åº¦å¯èƒ½è¾ƒå°
    
    ç»„åˆç­–ç•¥ï¼šLoss = CrossEntropy + Diceï¼Œå¹³è¡¡åƒç´ çº§å‡†ç¡®æ€§å’ŒåŒºåŸŸçº§å®Œæ•´æ€§
    
    è¿”å›:
        function: ç»„åˆæŸå¤±å‡½æ•°ï¼Œæ¥å—é¢„æµ‹å’ŒçœŸå®æ ‡ç­¾ï¼Œè¿”å›æŸå¤±å€¼
    """
    
    def dice_loss(y_pred, y_true, smooth=1e-6):
        """è®¡ç®—å•ä¸ªç±»åˆ«çš„DiceæŸå¤±
        
        DiceæŸå¤± = 1 - Diceç³»æ•°
        Diceç³»æ•° = 2 * |é¢„æµ‹âˆ©çœŸå®| / (|é¢„æµ‹| + |çœŸå®|)
        
        å‚æ•°:
            y_pred (Tensor): é¢„æµ‹æ¦‚ç‡ï¼Œå½¢çŠ¶ä¸º [N]ï¼Œå€¼èŒƒå›´ [0,1]
            y_true (Tensor): çœŸå®æ ‡ç­¾ï¼Œå½¢çŠ¶ä¸º [N]ï¼Œå€¼ä¸º 0 æˆ– 1
            smooth (float): å¹³æ»‘é¡¹ï¼Œé˜²æ­¢åˆ†æ¯ä¸º0ï¼Œæé«˜æ•°å€¼ç¨³å®šæ€§
            
        è¿”å›:
            Tensor: DiceæŸå¤±å€¼
        """
        # å±•å¹³å¼ é‡ï¼Œä¾¿äºè®¡ç®—
        y_pred = y_pred.contiguous().view(-1)
        y_true = y_true.contiguous().view(-1)
        
        # è®¡ç®—äº¤é›†ï¼šé¢„æµ‹ä¸ºæ­£ä¸”çœŸå®ä¸ºæ­£çš„åƒç´ æ•°
        intersection = (y_pred * y_true).sum()
        
        # è®¡ç®—Diceç³»æ•°ï¼Œç„¶åè½¬æ¢ä¸ºæŸå¤±ï¼ˆ1 - Diceï¼‰
        dice_coeff = (2. * intersection + smooth) / (y_pred.sum() + y_true.sum() + smooth)
        dice_loss_value = 1 - dice_coeff
        
        return dice_loss_value
    
    def combined_loss(y_pred, y_true):
        """ç»„åˆæŸå¤±å‡½æ•°ï¼šäº¤å‰ç†µ + DiceæŸå¤±
        
        å‚æ•°:
            y_pred (Tensor): æ¨¡å‹é¢„æµ‹logitsï¼Œå½¢çŠ¶ä¸º [B, C, D, H, W]
            y_true (Tensor): çœŸå®åˆ†å‰²æ ‡ç­¾ï¼Œå½¢çŠ¶ä¸º [B, D, H, W]
            
        è¿”å›:
            Tensor: ç»„åˆæŸå¤±å€¼
        """
        # ==================== äº¤å‰ç†µæŸå¤± ====================
        # å¤„ç†ç±»åˆ«ä¸å¹³è¡¡ï¼Œå¯ä»¥è€ƒè™‘åŠ æƒäº¤å‰ç†µ
        # è¿™é‡Œä½¿ç”¨æ ‡å‡†äº¤å‰ç†µï¼Œå¯¹æ‰€æœ‰ç±»åˆ«ç­‰æƒé‡å¤„ç†
        ce_loss = nn.CrossEntropyLoss()(y_pred, y_true)
        
        # ==================== DiceæŸå¤± ====================
        # å°†é¢„æµ‹logitsè½¬æ¢ä¸ºæ¦‚ç‡åˆ†å¸ƒ
        y_pred_softmax = torch.softmax(y_pred, dim=1)  # [B, C, D, H, W]
        
        # å°†çœŸå®æ ‡ç­¾è½¬æ¢ä¸ºone-hotç¼–ç 
        num_classes = y_pred.shape[1]
        y_true_one_hot = torch.zeros_like(y_pred_softmax)
        y_true_one_hot = y_true_one_hot.scatter_(1, y_true.unsqueeze(1), 1)
        
        # è®¡ç®—æ¯ä¸ªå‰æ™¯ç±»åˆ«çš„DiceæŸå¤±ï¼ˆè·³è¿‡èƒŒæ™¯ç±»åˆ«ï¼‰
        dice_loss_total = 0
        num_foreground_classes = 0
        
        for class_idx in range(1, num_classes):  # ä»1å¼€å§‹ï¼Œè·³è¿‡èƒŒæ™¯ç±»åˆ«ï¼ˆç´¢å¼•0ï¼‰
            # æå–å½“å‰ç±»åˆ«çš„é¢„æµ‹æ¦‚ç‡å’ŒçœŸå®æ ‡ç­¾
            pred_class = y_pred_softmax[:, class_idx]  # [B, D, H, W]
            true_class = y_true_one_hot[:, class_idx]  # [B, D, H, W]
            
            # åªæœ‰å½“çœŸå®æ ‡ç­¾ä¸­å­˜åœ¨è¯¥ç±»åˆ«æ—¶æ‰è®¡ç®—æŸå¤±
            if true_class.sum() > 0:
                dice_loss_total += dice_loss(pred_class, true_class)
                num_foreground_classes += 1
        
        # è®¡ç®—å¹³å‡DiceæŸå¤±
        if num_foreground_classes > 0:
            avg_dice_loss = dice_loss_total / num_foreground_classes
        else:
            # å¦‚æœæ²¡æœ‰å‰æ™¯ç±»åˆ«ï¼ŒDiceæŸå¤±ä¸º0
            avg_dice_loss = torch.tensor(0.0, device=y_pred.device, requires_grad=True)
        
        # ==================== ç»„åˆæŸå¤± ====================
        # å°†äº¤å‰ç†µæŸå¤±å’ŒDiceæŸå¤±ç›¸åŠ 
        # å¯ä»¥è€ƒè™‘æ·»åŠ æƒé‡ç³»æ•°æ¥å¹³è¡¡ä¸¤ç§æŸå¤±çš„è´¡çŒ®
        total_loss = ce_loss + avg_dice_loss
        
        return total_loss
    
    return combined_loss


def train_epoch(model, dataloader, optimizer, loss_fn, device, scaler=None, use_amp=False, epoch_num=0):
    """æ‰§è¡Œä¸€ä¸ªè®­ç»ƒå‘¨æœŸ
    
    åœ¨ä¸€ä¸ªepochä¸­éå†æ‰€æœ‰è®­ç»ƒæ•°æ®ï¼Œæ‰§è¡Œå‰å‘ä¼ æ’­ã€æŸå¤±è®¡ç®—ã€åå‘ä¼ æ’­å’Œå‚æ•°æ›´æ–°ã€‚
    æ”¯æŒæ··åˆç²¾åº¦è®­ç»ƒå’Œæ·±åº¦ç›‘ç£æœºåˆ¶ã€‚
    
    è®­ç»ƒæµç¨‹ï¼š
    1. è®¾ç½®æ¨¡å‹ä¸ºè®­ç»ƒæ¨¡å¼
    2. éå†æ•°æ®æ‰¹æ¬¡
    3. å‰å‘ä¼ æ’­è®¡ç®—é¢„æµ‹ç»“æœ
    4. è®¡ç®—æŸå¤±ï¼ˆåŒ…æ‹¬æ·±åº¦ç›‘ç£æŸå¤±ï¼‰
    5. åå‘ä¼ æ’­è®¡ç®—æ¢¯åº¦
    6. æ›´æ–°æ¨¡å‹å‚æ•°
    7. ç´¯è®¡æŸå¤±ç»Ÿè®¡
    
    å‚æ•°:
        model (nn.Module): è¦è®­ç»ƒçš„3D U-Netæ¨¡å‹
        dataloader (DataLoader): è®­ç»ƒæ•°æ®åŠ è½½å™¨
        optimizer (Optimizer): ä¼˜åŒ–å™¨ï¼ˆå¦‚Adamï¼‰
        loss_fn (function): æŸå¤±å‡½æ•°
        device (torch.device): è®¡ç®—è®¾å¤‡ï¼ˆCPUæˆ–GPUï¼‰
        scaler (GradScaler, å¯é€‰): æ··åˆç²¾åº¦è®­ç»ƒçš„æ¢¯åº¦ç¼©æ”¾å™¨
        use_amp (bool): æ˜¯å¦ä½¿ç”¨è‡ªåŠ¨æ··åˆç²¾åº¦è®­ç»ƒ
        epoch_num (int): å½“å‰epochç¼–å·
        
    è¿”å›:
        float: å½“å‰epochçš„å¹³å‡è®­ç»ƒæŸå¤±
    """
    # è®¾ç½®æ¨¡å‹ä¸ºè®­ç»ƒæ¨¡å¼ï¼Œå¯ç”¨dropoutå’Œbatch normalizationçš„è®­ç»ƒè¡Œä¸º
    model.train()
    
    # åˆå§‹åŒ–ç»Ÿè®¡å˜é‡
    epoch_loss = 0.0
    num_batches = len(dataloader)
    batch_times = []
    data_load_times = []
    forward_times = []
    backward_times = []
    
    print(f"\n{'='*60}")
    print(f"å¼€å§‹è®­ç»ƒ Epoch {epoch_num + 1}")
    print(f"æ€»æ‰¹æ¬¡æ•°: {num_batches}")
    print(f"ä½¿ç”¨è®¾å¤‡: {device}")
    print(f"æ··åˆç²¾åº¦è®­ç»ƒ: {'å¯ç”¨' if use_amp else 'ç¦ç”¨'}")
    print(f"{'='*60}")
    
    epoch_start_time = time.time()
    
    # åˆ›å»ºè®­ç»ƒè¿›åº¦æ¡
    train_pbar = tqdm(
        enumerate(dataloader), 
        total=num_batches,
        desc=f"Epoch {epoch_num + 1}/{epoch_num + 1} - è®­ç»ƒ",
        unit="batch",
        ncols=120,
        leave=False
    )
    
    # éå†è®­ç»ƒæ•°æ®æ‰¹æ¬¡
    for batch_idx, batch in train_pbar:
        batch_start_time = time.time()
        
        # ==================== æ•°æ®å‡†å¤‡ ====================
        data_start_time = time.time()
        # å°†æ•°æ®ç§»åŠ¨åˆ°æŒ‡å®šè®¾å¤‡ï¼ˆGPUæˆ–CPUï¼‰
        images = batch['image'].to(device, non_blocking=True)  # [B, 4, D, H, W]
        masks = batch['mask'].to(device, non_blocking=True)    # [B, D, H, W]
        data_load_time = time.time() - data_start_time
        data_load_times.append(data_load_time)
        
        # æ‰“å°æ•°æ®å½¢çŠ¶ä¿¡æ¯ï¼ˆå‰å‡ ä¸ªæ‰¹æ¬¡ï¼‰
        if batch_idx < 3:
            print(f"æ‰¹æ¬¡ {batch_idx + 1} - æ•°æ®å½¢çŠ¶: images={list(images.shape)}, masks={list(masks.shape)}")
            print(f"æ‰¹æ¬¡ {batch_idx + 1} - æ•°æ®åŠ è½½æ—¶é—´: {data_load_time:.3f}s")
        
        # æ¸…é›¶æ¢¯åº¦ï¼Œé˜²æ­¢æ¢¯åº¦ç´¯ç§¯
        optimizer.zero_grad()
        
        # ==================== å‰å‘ä¼ æ’­ ====================
        forward_start_time = time.time()
        
        if use_amp:
            # æ··åˆç²¾åº¦è®­ç»ƒè·¯å¾„
            with autocast('cuda'):
                # æ¨¡å‹å‰å‘ä¼ æ’­
                outputs = model(images)
                
                # å¤„ç†æ·±åº¦ç›‘ç£è¾“å‡º
                if isinstance(outputs, tuple):
                    # æ·±åº¦ç›‘ç£æ¨¡å¼ï¼šoutputs = (ä¸»è¾“å‡º, è¾…åŠ©è¾“å‡º1, è¾…åŠ©è¾“å‡º2, ...)
                    main_output = outputs[0]
                    auxiliary_outputs = outputs[1:]
                    
                    # è®¡ç®—ä¸»è¾“å‡ºçš„æŸå¤±
                    loss = loss_fn(main_output, masks)
                    
                    # æ·»åŠ è¾…åŠ©è¾“å‡ºçš„æŸå¤±ï¼Œæƒé‡é€’å‡
                    for i, aux_output in enumerate(auxiliary_outputs):
                        # æƒé‡ç³»æ•°ï¼š0.5, 0.25, 0.125, ...
                        weight = 0.5 ** (i + 1)
                        aux_loss = loss_fn(aux_output, masks)
                        loss += weight * aux_loss
                        
                    if batch_idx < 3:
                        print(f"æ‰¹æ¬¡ {batch_idx + 1} - æ·±åº¦ç›‘ç£: ä¸»æŸå¤±={loss_fn(main_output, masks):.4f}, è¾…åŠ©è¾“å‡ºæ•°={len(auxiliary_outputs)}")
                else:
                    # æ ‡å‡†æ¨¡å¼ï¼šåªæœ‰ä¸»è¾“å‡º
                    loss = loss_fn(outputs, masks)
            
            forward_time = time.time() - forward_start_time
            forward_times.append(forward_time)
            
            # ==================== åå‘ä¼ æ’­ï¼ˆæ··åˆç²¾åº¦ï¼‰====================
            backward_start_time = time.time()
            
            # ç¼©æ”¾æŸå¤±ä»¥é˜²æ­¢æ¢¯åº¦ä¸‹æº¢
            scaler.scale(loss).backward()
            
            # æ›´æ–°å‚æ•°
            scaler.step(optimizer)
            
            # æ›´æ–°ç¼©æ”¾å› å­
            scaler.update()
            
            backward_time = time.time() - backward_start_time
            backward_times.append(backward_time)
            
        else:
            # ==================== æ ‡å‡†ç²¾åº¦è®­ç»ƒè·¯å¾„ ====================
            # æ¨¡å‹å‰å‘ä¼ æ’­
            outputs = model(images)
            
            # å¤„ç†æ·±åº¦ç›‘ç£è¾“å‡º
            if isinstance(outputs, tuple):
                # æ·±åº¦ç›‘ç£æ¨¡å¼
                main_output = outputs[0]
                auxiliary_outputs = outputs[1:]
                
                # è®¡ç®—ä¸»è¾“å‡ºçš„æŸå¤±
                loss = loss_fn(main_output, masks)
                
                # æ·»åŠ è¾…åŠ©è¾“å‡ºçš„æŸå¤±ï¼Œæƒé‡é€’å‡
                for i, aux_output in enumerate(auxiliary_outputs):
                    weight = 0.5 ** (i + 1)
                    aux_loss = loss_fn(aux_output, masks)
                    loss += weight * aux_loss
                    
                if batch_idx < 3:
                    print(f"æ‰¹æ¬¡ {batch_idx + 1} - æ·±åº¦ç›‘ç£: ä¸»æŸå¤±={loss_fn(main_output, masks):.4f}, è¾…åŠ©è¾“å‡ºæ•°={len(auxiliary_outputs)}")
            else:
                # æ ‡å‡†æ¨¡å¼
                loss = loss_fn(outputs, masks)
            
            forward_time = time.time() - forward_start_time
            forward_times.append(forward_time)
            
            # ==================== åå‘ä¼ æ’­ï¼ˆæ ‡å‡†ç²¾åº¦ï¼‰====================
            backward_start_time = time.time()
            
            loss.backward()
            
            # å¯é€‰ï¼šæ¢¯åº¦è£å‰ªï¼Œé˜²æ­¢æ¢¯åº¦çˆ†ç‚¸
            # torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
            
            # æ›´æ–°å‚æ•°
            optimizer.step()
            
            backward_time = time.time() - backward_start_time
            backward_times.append(backward_time)
        
        # ==================== æŸå¤±ç»Ÿè®¡å’Œè¿›åº¦æ˜¾ç¤º ====================
        # ç´¯è®¡å½“å‰æ‰¹æ¬¡çš„æŸå¤±
        epoch_loss += loss.item()
        batch_time = time.time() - batch_start_time
        batch_times.append(batch_time)
        
        # æ›´æ–°è¿›åº¦æ¡
        avg_batch_time = sum(batch_times) / len(batch_times)
        current_loss = epoch_loss / (batch_idx + 1)
        
        # GPUå†…å­˜ä½¿ç”¨æƒ…å†µ
        if torch.cuda.is_available():
            gpu_memory = torch.cuda.memory_allocated(device) / 1024**3  # GB
            memory_info = f"GPU:{gpu_memory:.1f}GB"
        else:
            memory_info = "CPU"
        
        # æ›´æ–°è¿›åº¦æ¡æè¿°
        train_pbar.set_postfix({
            'Loss': f'{loss.item():.4f}',
            'AvgLoss': f'{current_loss:.4f}',
            'Time': f'{batch_time:.2f}s',
            'Memory': memory_info,
            'LR': f'{optimizer.param_groups[0]["lr"]:.1e}'
        })
        
        # è¯¦ç»†ä¿¡æ¯è¾“å‡ºï¼ˆå‰å‡ ä¸ªæ‰¹æ¬¡å’Œå…³é”®èŠ‚ç‚¹ï¼‰
        if batch_idx < 3 or batch_idx % max(1, num_batches // 10) == 0:
            eta_seconds = avg_batch_time * (num_batches - batch_idx - 1)
            eta_minutes = eta_seconds / 60
            
            tqdm.write(f"[è¯¦ç»†] æ‰¹æ¬¡ {batch_idx+1}: æŸå¤±={loss.item():.6f}, "
                      f"æ•°æ®åŠ è½½={data_load_times[-1]:.3f}s, "
                      f"å‰å‘={forward_times[-1]:.3f}s, "
                      f"åå‘={backward_times[-1]:.3f}s, "
                      f"ETA={eta_minutes:.1f}min")
    
    # å…³é—­è®­ç»ƒè¿›åº¦æ¡
    train_pbar.close()
    
    # Epochç»“æŸç»Ÿè®¡
    epoch_time = time.time() - epoch_start_time
    avg_epoch_loss = epoch_loss / num_batches
    
    print(f"\n{'='*60}")
    print(f"Epoch {epoch_num + 1} è®­ç»ƒå®Œæˆ!")
    print(f"æ€»æ—¶é—´: {epoch_time:.2f}s ({epoch_time/60:.1f}min)")
    print(f"å¹³å‡æ‰¹æ¬¡æ—¶é—´: {sum(batch_times)/len(batch_times):.3f}s")
    print(f"å¹³å‡æ•°æ®åŠ è½½æ—¶é—´: {sum(data_load_times)/len(data_load_times):.3f}s")
    print(f"å¹³å‡å‰å‘ä¼ æ’­æ—¶é—´: {sum(forward_times)/len(forward_times):.3f}s")
    print(f"å¹³å‡åå‘ä¼ æ’­æ—¶é—´: {sum(backward_times)/len(backward_times):.3f}s")
    print(f"å¹³å‡è®­ç»ƒæŸå¤±: {avg_epoch_loss:.6f}")
    print(f"{'='*60}\n")
    
    return avg_epoch_loss


def validate(model, dataloader, loss_fn, device, args):
    """æ¨¡å‹éªŒè¯è¯„ä¼°
    
    åœ¨éªŒè¯é›†ä¸Šè¯„ä¼°æ¨¡å‹æ€§èƒ½ï¼Œè®¡ç®—æŸå¤±å’Œå…³é”®è¯„ä¼°æŒ‡æ ‡ã€‚
    éªŒè¯è¿‡ç¨‹ä¸æ›´æ–°æ¨¡å‹å‚æ•°ï¼Œç”¨äºç›‘æ§è®­ç»ƒè¿›åº¦å’Œé˜²æ­¢è¿‡æ‹Ÿåˆã€‚
    
    è¯„ä¼°æŒ‡æ ‡ï¼š
    1. éªŒè¯æŸå¤±ï¼šä¸è®­ç»ƒæŸå¤±ç›¸åŒçš„æŸå¤±å‡½æ•°
    2. Diceç³»æ•°ï¼šè¯„ä¼°åˆ†å‰²é‡å åº¦ï¼Œå€¼è¶Šé«˜è¶Šå¥½
    3. Hausdorffè·ç¦»ï¼šè¯„ä¼°è¾¹ç•Œå‡†ç¡®æ€§ï¼Œå€¼è¶Šå°è¶Šå¥½
    
    éªŒè¯æµç¨‹ï¼š
    1. è®¾ç½®æ¨¡å‹ä¸ºè¯„ä¼°æ¨¡å¼
    2. ç¦ç”¨æ¢¯åº¦è®¡ç®—ä»¥èŠ‚çœå†…å­˜
    3. éå†éªŒè¯æ•°æ®
    4. è®¡ç®—é¢„æµ‹ç»“æœå’Œè¯„ä¼°æŒ‡æ ‡
    5. ç»Ÿè®¡å¹³å‡æ€§èƒ½
    
    å‚æ•°:
        model (nn.Module): è¦è¯„ä¼°çš„æ¨¡å‹
        dataloader (DataLoader): éªŒè¯æ•°æ®åŠ è½½å™¨
        loss_fn (function): æŸå¤±å‡½æ•°
        device (torch.device): è®¡ç®—è®¾å¤‡
        args (Namespace): åŒ…å«æ¨¡å‹é…ç½®çš„å‚æ•°å¯¹è±¡
        
    è¿”å›:
        tuple: (å¹³å‡éªŒè¯æŸå¤±, å¹³å‡Diceç³»æ•°, å¹³å‡Hausdorffè·ç¦»)
    """
    # è®¾ç½®æ¨¡å‹ä¸ºè¯„ä¼°æ¨¡å¼ï¼Œç¦ç”¨dropoutå’Œbatch normalizationçš„éšæœºæ€§
    model.eval()
    
    # åˆå§‹åŒ–ç»Ÿè®¡å˜é‡
    val_loss = 0.0
    dice_scores = []
    hausdorff_distances = []
    num_batches = len(dataloader)
    
    # åˆ›å»ºéªŒè¯è¿›åº¦æ¡
    val_pbar = tqdm(
        enumerate(dataloader),
        total=num_batches,
        desc="éªŒè¯ä¸­",
        unit="batch",
        ncols=100,
        leave=False
    )
    
    # ç¦ç”¨æ¢¯åº¦è®¡ç®—ï¼ŒèŠ‚çœå†…å­˜å¹¶åŠ é€Ÿæ¨ç†
    with torch.no_grad():
        for batch_idx, batch in val_pbar:
            # ==================== æ•°æ®å‡†å¤‡ ====================
            images = batch['image'].to(device, non_blocking=True)
            masks = batch['mask'].to(device, non_blocking=True)
            
            # ==================== æ¨¡å‹æ¨ç† ====================
            outputs = model(images)
            
            # å¤„ç†æ·±åº¦ç›‘ç£è¾“å‡ºï¼Œåªä½¿ç”¨ä¸»è¾“å‡ºè¿›è¡Œè¯„ä¼°
            if isinstance(outputs, tuple):
                main_output = outputs[0]  # ä½¿ç”¨ä¸»è¾“å‡º
                outputs = main_output
            
            # ==================== æŸå¤±è®¡ç®— ====================
            loss = loss_fn(outputs, masks)
            val_loss += loss.item()
            
            # ==================== è¯„ä¼°æŒ‡æ ‡è®¡ç®— ====================
            try:
                # è®¡ç®—å¤šç±»åˆ«Diceç³»æ•°
                class_dice_scores, avg_dice = multiclass_dice_coefficient(
                    outputs, masks, num_classes=args.out_channels
                )
                dice_scores.append(avg_dice.item())
                
                # è®¡ç®—å¤šç±»åˆ«Hausdorffè·ç¦»
                class_hausdorff_distances, avg_hausdorff = multiclass_hausdorff_distance(
                    outputs, masks, num_classes=args.out_channels
                )
                hausdorff_distances.append(avg_hausdorff)
                
            except Exception as e:
                print(f"è­¦å‘Šï¼šæ‰¹æ¬¡ {batch_idx} çš„æŒ‡æ ‡è®¡ç®—å¤±è´¥: {str(e)}")
                # å¦‚æœæŒ‡æ ‡è®¡ç®—å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤å€¼
                dice_scores.append(0.0)
                hausdorff_distances.append(float('inf'))
            
            # æ›´æ–°éªŒè¯è¿›åº¦æ¡
            current_dice = dice_scores[-1] if dice_scores else 0.0
            current_hausdorff = hausdorff_distances[-1] if hausdorff_distances else float('inf')
            
            val_pbar.set_postfix({
                'Loss': f'{loss.item():.4f}',
                'Dice': f'{current_dice:.4f}',
                'HD': f'{current_hausdorff:.2f}' if current_hausdorff != float('inf') else 'inf'
            })
    
    # å…³é—­éªŒè¯è¿›åº¦æ¡
    val_pbar.close()
    
    # ==================== ç»Ÿè®¡ç»“æœ ====================
    # è®¡ç®—å¹³å‡éªŒè¯æŸå¤±
    avg_val_loss = val_loss / num_batches
    
    # è®¡ç®—å¹³å‡Diceç³»æ•°
    if dice_scores:
        avg_dice = sum(dice_scores) / len(dice_scores)
    else:
        avg_dice = 0.0
        print("è­¦å‘Šï¼šæ²¡æœ‰æœ‰æ•ˆçš„Diceåˆ†æ•°")
    
    # è®¡ç®—å¹³å‡Hausdorffè·ç¦»
    if hausdorff_distances:
        # è¿‡æ»¤æ‰æ— ç©·å¤§å€¼
        valid_hausdorff = [h for h in hausdorff_distances if h != float('inf')]
        if valid_hausdorff:
            avg_hausdorff = sum(valid_hausdorff) / len(valid_hausdorff)
        else:
            avg_hausdorff = float('inf')
            print("è­¦å‘Šï¼šæ‰€æœ‰Hausdorffè·ç¦»éƒ½æ˜¯æ— ç©·å¤§")
    else:
        avg_hausdorff = float('inf')
        print("è­¦å‘Šï¼šæ²¡æœ‰æœ‰æ•ˆçš„Hausdorffè·ç¦»")
    
    return avg_val_loss, avg_dice, avg_hausdorff


def save_checkpoint(model, optimizer, epoch, best_dice, args, filename):
    """ä¿å­˜æ£€æŸ¥ç‚¹"""
    if args.distributed:
        model_state = model.module.state_dict()
    else:
        model_state = model.state_dict()
    
    state = {
        'epoch': epoch,
        'model_state': model_state,
        'optimizer_state': optimizer.state_dict(),
        'best_dice': best_dice,
        'args': args
    }
    
    torch.save(state, filename)


def main():
    args = parse_args()
    
    print("="*100)
    print("3D U-Net BraTS2021 è®­ç»ƒå¼€å§‹")
    print("="*100)
    
    # æ‰“å°è®­ç»ƒé…ç½®
    print("è®­ç»ƒé…ç½®:")
    print(f"  æ•°æ®ç›®å½•: {args.data_dir}")
    print(f"  è¾“å‡ºç›®å½•: {args.output_dir}")
    print(f"  æ‰¹æ¬¡å¤§å°: {args.batch_size}")
    print(f"  è®­ç»ƒè½®æ•°: {args.epochs}")
    print(f"  å­¦ä¹ ç‡: {args.lr}")
    print(f"  ç›®æ ‡å½¢çŠ¶: {args.target_shape}")
    print(f"  æ··åˆç²¾åº¦: {'å¯ç”¨' if args.amp else 'ç¦ç”¨'}")
    print(f"  æ·±åº¦ç›‘ç£: {'å¯ç”¨' if args.deep_supervision else 'ç¦ç”¨'}")
    print(f"  æ®‹å·®è¿æ¥: {'å¯ç”¨' if args.residual else 'ç¦ç”¨'}")
    print(f"  å·¥ä½œè¿›ç¨‹: {args.num_workers}")
    print("-"*50)
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    os.makedirs(args.output_dir, exist_ok=True)
    os.makedirs(os.path.join(args.output_dir, 'checkpoints'), exist_ok=True)
    os.makedirs(os.path.join(args.output_dir, 'visualizations'), exist_ok=True)
    print(f"è¾“å‡ºç›®å½•å·²åˆ›å»º: {args.output_dir}")
    
    # è®¾ç½®åˆ†å¸ƒå¼è®­ç»ƒ
    setup_distributed(args)
    
    # è®¾ç½®è®¾å¤‡
    if torch.cuda.is_available():
        if args.local_rank >= 0:
            device = torch.device(f'cuda:{args.local_rank}')
        else:
            device = torch.device('cuda')
        
        # æ‰“å°GPUä¿¡æ¯
        print(f"ä½¿ç”¨è®¾å¤‡: {device}")
        print(f"GPUåç§°: {torch.cuda.get_device_name(device)}")
        print(f"GPUå†…å­˜: {torch.cuda.get_device_properties(device).total_memory / 1024**3:.1f} GB")
        print(f"CUDAç‰ˆæœ¬: {torch.version.cuda}")
        print(f"PyTorchç‰ˆæœ¬: {torch.__version__}")
    else:
        device = torch.device('cpu')
        print("ä½¿ç”¨è®¾å¤‡: CPU")
    print("-"*50)
    
    # è·å–æ•°æ®åŠ è½½å™¨
    print("æ­£åœ¨åŠ è½½æ•°æ®...")
    train_loader, val_loader, test_loader = get_data_loaders(
        data_dir=args.data_dir,
        batch_size=args.batch_size,
        num_workers=args.num_workers,
        target_shape=args.target_shape
    )
    
    print("æ•°æ®åŠ è½½å®Œæˆ:")
    print(f"  è®­ç»ƒé›†: {len(train_loader.dataset)} ä¸ªæ ·æœ¬, {len(train_loader)} ä¸ªæ‰¹æ¬¡")
    print(f"  éªŒè¯é›†: {len(val_loader.dataset)} ä¸ªæ ·æœ¬, {len(val_loader)} ä¸ªæ‰¹æ¬¡")
    print(f"  æµ‹è¯•é›†: {len(test_loader.dataset)} ä¸ªæ ·æœ¬, {len(test_loader)} ä¸ªæ‰¹æ¬¡")
    print("-"*50)
    
    # åˆ›å»ºæ¨¡å‹
    print("æ­£åœ¨åˆ›å»ºæ¨¡å‹...")
    model = get_model(args).to(device)
    
    # è®¡ç®—æ¨¡å‹å‚æ•°æ•°é‡
    total_params = sum(p.numel() for p in model.parameters())
    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
    
    print("æ¨¡å‹ä¿¡æ¯:")
    print(f"  æ¨¡å‹ç±»å‹: 3D U-Net")
    print(f"  è¾“å…¥é€šé“: {args.in_channels}")
    print(f"  è¾“å‡ºé€šé“: {args.out_channels}")
    print(f"  ç‰¹å¾å±‚çº§: {args.features}")
    print(f"  æ€»å‚æ•°é‡: {total_params:,}")
    print(f"  å¯è®­ç»ƒå‚æ•°: {trainable_params:,}")
    print(f"  æ¨¡å‹å¤§å°: {total_params * 4 / 1024**2:.1f} MB (FP32)")
    print("-"*50)
    
    # åˆ†å¸ƒå¼è®­ç»ƒè®¾ç½®
    if args.distributed:
        model = DDP(model, device_ids=[args.local_rank], output_device=args.local_rank)
    
    # åˆ›å»ºä¼˜åŒ–å™¨
    optimizer = optim.Adam(model.parameters(), lr=args.lr, weight_decay=args.weight_decay)
    
    # åˆ›å»ºå­¦ä¹ ç‡è°ƒåº¦å™¨
    scheduler = optim.lr_scheduler.ReduceLROnPlateau(
        optimizer, mode='max', factor=0.5, patience=5
    )
    
    # è·å–æŸå¤±å‡½æ•°
    loss_fn = get_loss_function()
    
    # åˆ›å»ºæ··åˆç²¾åº¦è®­ç»ƒçš„ç¼©æ”¾å™¨
    scaler = GradScaler() if args.amp else None
    
    # åˆ›å»ºTensorBoardå†™å…¥å™¨
    if args.rank == 0:
        writer = SummaryWriter(log_dir=os.path.join(args.output_dir, 'logs'))
    
    # è®­ç»ƒå¾ªç¯
    best_dice = 0
    patience_counter = 0
    
    # åˆ›å»ºæ€»ä½“è®­ç»ƒè¿›åº¦æ¡
    epoch_pbar = tqdm(
        range(args.epochs),
        desc="æ€»ä½“è®­ç»ƒè¿›åº¦",
        unit="epoch",
        ncols=120,
        position=0
    )
    
    for epoch in epoch_pbar:
        # è®­ç»ƒä¸€ä¸ªepoch
        train_loss = train_epoch(
            model, train_loader, optimizer, loss_fn, device, scaler, args.amp, epoch
        )
        
        # éªŒè¯
        val_loss, val_dice, val_hausdorff = validate(model, val_loader, loss_fn, device, args)
        
        # æ›´æ–°å­¦ä¹ ç‡
        scheduler.step(val_dice)
        
        # æ›´æ–°æ€»ä½“è¿›åº¦æ¡
        epoch_pbar.set_postfix({
            'TrainLoss': f'{train_loss:.4f}',
            'ValLoss': f'{val_loss:.4f}',
            'ValDice': f'{val_dice:.4f}',
            'BestDice': f'{best_dice:.4f}',
            'Patience': f'{patience_counter}/{args.patience}',
            'LR': f'{optimizer.param_groups[0]["lr"]:.1e}'
        })
        
        # è®°å½•æŒ‡æ ‡
        if args.rank == 0:
            # ä½¿ç”¨tqdm.writeæ¥é¿å…ä¸è¿›åº¦æ¡å†²çª
            tqdm.write(f"\n{'*'*80}")
            tqdm.write(f"EPOCH {epoch+1}/{args.epochs} æ€»ç»“")
            tqdm.write(f"{'*'*80}")
            tqdm.write(f"è®­ç»ƒæŸå¤±:     {train_loss:.6f}")
            tqdm.write(f"éªŒè¯æŸå¤±:     {val_loss:.6f}")
            tqdm.write(f"éªŒè¯Diceç³»æ•°: {val_dice:.6f}")
            tqdm.write(f"éªŒè¯Hausdorff: {val_hausdorff:.4f}")
            tqdm.write(f"å½“å‰å­¦ä¹ ç‡:   {optimizer.param_groups[0]['lr']:.2e}")
            tqdm.write(f"æœ€ä½³Dice:     {best_dice:.6f}")
            tqdm.write(f"æ—©åœè®¡æ•°:     {patience_counter}/{args.patience}")
            
            # æ€§èƒ½è¶‹åŠ¿åˆ†æ
            if epoch > 0:
                tqdm.write(f"\næ€§èƒ½å˜åŒ–:")
                if val_dice > best_dice:
                    tqdm.write(f"  âœ“ Diceç³»æ•°æå‡: {val_dice - best_dice:+.6f}")
                else:
                    tqdm.write(f"  âœ— Diceç³»æ•°ä¸‹é™: {val_dice - best_dice:+.6f}")
            
            tqdm.write(f"{'*'*80}\n")
            
            writer.add_scalar('Loss/train', train_loss, epoch)
            writer.add_scalar('Loss/val', val_loss, epoch)
            writer.add_scalar('Metrics/dice', val_dice, epoch)
            writer.add_scalar('Metrics/hausdorff', val_hausdorff, epoch)
            writer.add_scalar('LR', optimizer.param_groups[0]['lr'], epoch)
            
            # å¯è§†åŒ–é¢„æµ‹ç»“æœ
            if (epoch + 1) % args.vis_freq == 0:
                with torch.no_grad():
                    # è·å–ä¸€ä¸ªæ‰¹æ¬¡çš„éªŒè¯æ•°æ®
                    val_batch = next(iter(val_loader))
                    val_images = val_batch['image'].to(device)
                    val_masks = val_batch['mask'].to(device)
                    
                    # è·å–é¢„æµ‹ç»“æœ
                    val_outputs = model(val_images)
                    if isinstance(val_outputs, tuple):
                        val_outputs = val_outputs[0]
                    
                    # ä¿å­˜å¯è§†åŒ–ç»“æœ
                    save_prediction_visualization(
                        val_images, val_masks, val_outputs,
                        os.path.join(args.output_dir, 'visualizations', f'epoch_{epoch+1}.png')
                    )
        
        # ä¿å­˜æœ€ä½³æ¨¡å‹
        if val_dice > best_dice:
            best_dice = val_dice
            patience_counter = 0
            
            if args.rank == 0:
                save_checkpoint(
                    model, optimizer, epoch, best_dice, args,
                    os.path.join(args.output_dir, 'checkpoints', 'best_model.pth')
                )
                tqdm.write(f'âœ“ æ–°çš„æœ€ä½³æ¨¡å‹å·²ä¿å­˜ï¼ŒDice: {best_dice:.4f}')
        else:
            patience_counter += 1
        
        # ä¿å­˜æœ€æ–°æ¨¡å‹
        if args.rank == 0 and (epoch + 1) % 10 == 0:
            save_checkpoint(
                model, optimizer, epoch, best_dice, args,
                os.path.join(args.output_dir, 'checkpoints', f'model_epoch_{epoch+1}.pth')
            )
        
        # æ—©åœ
        if patience_counter >= args.patience:
            tqdm.write(f'âš  æ—©åœè§¦å‘ï¼Œåœ¨ç¬¬ {epoch+1} è½®åœæ­¢è®­ç»ƒ')
            break
    
    # å…³é—­è¿›åº¦æ¡å’ŒTensorBoardå†™å…¥å™¨
    epoch_pbar.close()
    if args.rank == 0:
        writer.close()
    
    # åœ¨æµ‹è¯•é›†ä¸Šè¯„ä¼°æœ€ä½³æ¨¡å‹
    if args.rank == 0:
        print('\n' + '='*60)
        print('æ­£åœ¨è¯„ä¼°æœ€ä½³æ¨¡å‹...')
        print('='*60)
        
        # åŠ è½½æœ€ä½³æ¨¡å‹
        checkpoint = torch.load(os.path.join(args.output_dir, 'checkpoints', 'best_model.pth'))
        
        if args.distributed:
            model.module.load_state_dict(checkpoint['model_state'])
        else:
            model.load_state_dict(checkpoint['model_state'])
        
        # åœ¨æµ‹è¯•é›†ä¸Šè¯„ä¼°
        test_loss, test_dice, test_hausdorff = validate(model, test_loader, loss_fn, device, args)
        
        print('\n' + '='*60)
        print('æœ€ç»ˆæµ‹è¯•ç»“æœ:')
        print('='*60)
        print(f'æµ‹è¯•æŸå¤±:      {test_loss:.6f}')
        print(f'æµ‹è¯•Diceç³»æ•°:  {test_dice:.6f}')
        print(f'æµ‹è¯•Hausdorff: {test_hausdorff:.4f}')
        print('='*60)
        print('è®­ç»ƒå®Œæˆ! ğŸ‰')
        print('='*60)


if __name__ == '__main__':
    main()