# 3D U-Netè®­ç»ƒè„šæœ¬ä¼˜åŒ–æ€»ç»“

## ä¼˜åŒ–æ¦‚è§ˆ

æœ¬æ¬¡ä¼˜åŒ–åœ¨ä¿æŒåŸæœ‰ä»£ç ç»“æ„çš„åŸºç¡€ä¸Šï¼Œå¯¹è®­ç»ƒè„šæœ¬è¿›è¡Œäº†å…¨é¢çš„æ€§èƒ½å’ŒåŠŸèƒ½å¢å¼ºï¼Œä¸»è¦åŒ…æ‹¬ä»¥ä¸‹å‡ ä¸ªæ–¹é¢ï¼š

## ğŸš€ ä¸»è¦ä¼˜åŒ–å†…å®¹

### 1. å‚æ•°é…ç½®å¢å¼º
- **ä¼˜åŒ–å™¨é€‰æ‹©**: æ”¯æŒAdamã€AdamWã€SGDå¤šç§ä¼˜åŒ–å™¨
- **å­¦ä¹ ç‡è°ƒåº¦**: æ”¯æŒPlateauã€Cosineã€Stepã€Exponentialå¤šç§è°ƒåº¦ç­–ç•¥
- **æŸå¤±å‡½æ•°**: æ–°å¢Focal Lossæ”¯æŒï¼Œå¯é…ç½®æŸå¤±æƒé‡
- **æ•°æ®å¢å¼º**: å¯é…ç½®çš„æ•°æ®å¢å¼ºå‚æ•°
- **æ¢¯åº¦ä¼˜åŒ–**: æ”¯æŒæ¢¯åº¦è£å‰ªå’Œæ¢¯åº¦ç´¯ç§¯

### 2. æŸå¤±å‡½æ•°ä¼˜åŒ–
```python
# æ–°å¢Focal Lossç±»
class FocalLoss(nn.Module):
    """ä¸“é—¨å¤„ç†ç±»åˆ«ä¸å¹³è¡¡é—®é¢˜"""
    
# æ”¹è¿›çš„ç»„åˆæŸå¤±å‡½æ•°
def get_loss_function(args):
    """æ”¯æŒå¤šç§æŸå¤±ç±»å‹ç»„åˆ"""
```

**ä¼˜åŠ¿**:
- Focal Lossæœ‰æ•ˆå¤„ç†ç±»åˆ«ä¸å¹³è¡¡
- å¯é…ç½®çš„æŸå¤±æƒé‡å¹³è¡¡
- æ›´ç¨³å®šçš„DiceæŸå¤±è®¡ç®—
- æ”¯æŒTverskyæŸå¤±ï¼ˆå¯æ‰©å±•ï¼‰

### 3. è®­ç»ƒæµç¨‹ä¼˜åŒ–

#### æ¢¯åº¦ç´¯ç§¯
```python
# æ”¯æŒæ¢¯åº¦ç´¯ç§¯æ¨¡æ‹Ÿå¤§æ‰¹æ¬¡è®­ç»ƒ
accumulation_steps = args.accumulation_steps
loss = loss / accumulation_steps  # ç¼©æ”¾æŸå¤±
```

**ä¼˜åŠ¿**:
- åœ¨GPUå†…å­˜æœ‰é™æ—¶æ¨¡æ‹Ÿå¤§æ‰¹æ¬¡è®­ç»ƒ
- æé«˜è®­ç»ƒç¨³å®šæ€§
- æ›´å¥½çš„æ¢¯åº¦ä¼°è®¡

#### æ¢¯åº¦è£å‰ª
```python
# é˜²æ­¢æ¢¯åº¦çˆ†ç‚¸
if args.gradient_clipping > 0:
    torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=args.gradient_clipping)
```

#### æ·±åº¦ç›‘ç£ä¼˜åŒ–
```python
def compute_loss_with_deep_supervision(outputs, masks, loss_fn, batch_idx):
    """ç»Ÿä¸€å¤„ç†æ·±åº¦ç›‘ç£æŸå¤±è®¡ç®—"""
```

### 4. ç›‘æ§å’Œæ—¥å¿—å¢å¼º

#### è¯¦ç»†çš„æ€§èƒ½ç»Ÿè®¡
```python
# è¿”å›è¯¦ç»†çš„è®­ç»ƒç»Ÿè®¡
return {
    'avg_total_loss': avg_total_loss,
    'avg_base_loss': avg_base_loss,
    'avg_dice_loss': avg_dice_loss,
    'epoch_time': epoch_time,
    'avg_batch_time': avg_batch_time,
    'avg_gpu_memory': avg_gpu_memory,
    'max_gpu_memory': max_gpu_memory
}
```

#### å¢å¼ºçš„TensorBoardæ—¥å¿—
- åˆ†ç¦»çš„æŸå¤±ç»„ä»¶è®°å½•
- æ€§èƒ½æŒ‡æ ‡ç›‘æ§
- GPUå†…å­˜ä½¿ç”¨è¿½è¸ª
- å­¦ä¹ ç‡å˜åŒ–è®°å½•

### 5. æ£€æŸ¥ç‚¹å’Œæ¢å¤åŠŸèƒ½

#### å®Œæ•´çš„æ£€æŸ¥ç‚¹ä¿å­˜
```python
def save_checkpoint(model, optimizer, scheduler, epoch, best_dice, patience_counter, args, filename):
    """ä¿å­˜å®Œæ•´çš„è®­ç»ƒçŠ¶æ€"""
```

#### æ™ºèƒ½æ¢å¤è®­ç»ƒ
```python
def load_checkpoint(checkpoint_path, model, optimizer, scheduler, args):
    """ä»æ£€æŸ¥ç‚¹æ¢å¤è®­ç»ƒ"""
```

#### é¢„è®­ç»ƒæ¨¡å‹æ”¯æŒ
```python
def load_pretrained_model(pretrained_path, model, args):
    """åŠ è½½é¢„è®­ç»ƒæ¨¡å‹ï¼Œè‡ªåŠ¨å¤„ç†å‚æ•°åŒ¹é…"""
```

### 6. é…ç½®ç®¡ç†ä¼˜åŒ–

#### è®­ç»ƒé…ç½®ä¿å­˜
```python
def save_training_config(args):
    """è‡ªåŠ¨ä¿å­˜è®­ç»ƒé…ç½®åˆ°JSONæ–‡ä»¶"""
```

#### çµæ´»çš„éªŒè¯é¢‘ç‡
```python
# æ”¯æŒè‡ªå®šä¹‰éªŒè¯é¢‘ç‡
if (epoch + 1) % args.val_freq == 0:
    validate(...)
```

## ğŸ“Š æ€§èƒ½æå‡

### å†…å­˜ä¼˜åŒ–
- **æ¢¯åº¦ç´¯ç§¯**: å‡å°‘GPUå†…å­˜éœ€æ±‚
- **æ··åˆç²¾åº¦è®­ç»ƒ**: é™ä½å†…å­˜ä½¿ç”¨50%
- **æ™ºèƒ½æ•°æ®åŠ è½½**: ä¼˜åŒ–æ•°æ®ä¼ è¾“æ•ˆç‡

### è®­ç»ƒç¨³å®šæ€§
- **æ¢¯åº¦è£å‰ª**: é˜²æ­¢æ¢¯åº¦çˆ†ç‚¸
- **æ”¹è¿›çš„æŸå¤±å‡½æ•°**: æ›´ç¨³å®šçš„æ•°å€¼è®¡ç®—
- **å­¦ä¹ ç‡è°ƒåº¦**: æ›´å¥½çš„æ”¶æ•›æ€§

### ç›‘æ§èƒ½åŠ›
- **å®æ—¶æ€§èƒ½ç›‘æ§**: GPUå†…å­˜ã€è®­ç»ƒæ—¶é—´ç­‰
- **è¯¦ç»†çš„æŸå¤±åˆ†è§£**: ä¾¿äºè°ƒè¯•å’Œä¼˜åŒ–
- **è‡ªåŠ¨é…ç½®ä¿å­˜**: ä¾¿äºå®éªŒå¤ç°

## ğŸ› ï¸ ä½¿ç”¨æ–¹å¼

### åŸºç¡€è®­ç»ƒ
```bash
python train.py \
    --data_dir ./data/BraTS2021_Training_Data \
    --output_dir ./output/experiment_1 \
    --batch_size 2 \
    --epochs 100 \
    --amp \
    --residual
```

### é«˜çº§é…ç½®
```bash
python train.py \
    --data_dir ./data/BraTS2021_Training_Data \
    --output_dir ./output/experiment_advanced \
    --batch_size 1 \
    --epochs 100 \
    --optimizer adamw \
    --scheduler cosine \
    --focal_loss \
    --deep_supervision \
    --gradient_clipping 1.0 \
    --accumulation_steps 4 \
    --loss_weights 1.0 2.0
```

### æ¢å¤è®­ç»ƒ
```bash
python train.py \
    --resume ./output/experiment_1/checkpoints/latest.pth \
    --lr 5e-5
```

### ä»…æµ‹è¯•
```bash
python train.py \
    --resume ./output/experiment_1/checkpoints/best_model.pth \
    --test_only
```

## ğŸ“ˆ æ–°å¢åŠŸèƒ½ç‰¹æ€§

### 1. å¤šä¼˜åŒ–å™¨æ”¯æŒ
- **Adam**: é»˜è®¤é€‰æ‹©ï¼Œé€‚åˆå¤§å¤šæ•°æƒ…å†µ
- **AdamW**: æ”¹è¿›çš„æƒé‡è¡°å‡ï¼Œé€šå¸¸æ€§èƒ½æ›´å¥½
- **SGD**: ç»å…¸ä¼˜åŒ–å™¨ï¼ŒæŸäº›æƒ…å†µä¸‹æ”¶æ•›æ›´ç¨³å®š

### 2. å¤šè°ƒåº¦å™¨æ”¯æŒ
- **ReduceLROnPlateau**: åŸºäºéªŒè¯æŒ‡æ ‡è‡ªé€‚åº”è°ƒæ•´
- **CosineAnnealingLR**: ä½™å¼¦é€€ç«ï¼Œå¹³æ»‘çš„å­¦ä¹ ç‡å˜åŒ–
- **StepLR**: é˜¶æ¢¯å¼è¡°å‡
- **ExponentialLR**: æŒ‡æ•°è¡°å‡

### 3. æŸå¤±å‡½æ•°å¢å¼º
- **Focal Loss**: å¤„ç†ç±»åˆ«ä¸å¹³è¡¡
- **å¯é…ç½®æƒé‡**: å¹³è¡¡ä¸åŒæŸå¤±ç»„ä»¶
- **æ”¹è¿›çš„DiceæŸå¤±**: æ›´ç¨³å®šçš„æ•°å€¼è®¡ç®—

### 4. è®­ç»ƒæ§åˆ¶
- **æ¢¯åº¦ç´¯ç§¯**: æ¨¡æ‹Ÿå¤§æ‰¹æ¬¡è®­ç»ƒ
- **æ¢¯åº¦è£å‰ª**: é˜²æ­¢æ¢¯åº¦çˆ†ç‚¸
- **è‡ªå®šä¹‰éªŒè¯é¢‘ç‡**: èŠ‚çœè®¡ç®—èµ„æº
- **çµæ´»çš„ä¿å­˜ç­–ç•¥**: å®šæœŸä¿å­˜å’Œæœ€ä½³æ¨¡å‹ä¿å­˜

## ğŸ”§ é…ç½®å»ºè®®

### GPUå†…å­˜ä¼˜åŒ–
```python
# å°GPUå†…å­˜ (< 8GB)
--batch_size 1
--accumulation_steps 4
--target_shape 96 96 96

# ä¸­ç­‰GPUå†…å­˜ (8-16GB)
--batch_size 2
--accumulation_steps 2
--target_shape 128 128 128

# å¤§GPUå†…å­˜ (> 16GB)
--batch_size 4
--target_shape 160 160 160
```

### è®­ç»ƒç­–ç•¥å»ºè®®
```python
# å¿«é€ŸåŸå‹éªŒè¯
--epochs 50
--val_freq 2
--save_freq 10

# å®Œæ•´è®­ç»ƒ
--epochs 200
--patience 20
--val_freq 1
--save_freq 5

# ç²¾ç»†è°ƒä¼˜
--lr 5e-5
--scheduler cosine
--gradient_clipping 0.5
```

## ğŸ“‹ å…¼å®¹æ€§è¯´æ˜

### å‘åå…¼å®¹
- ä¿æŒåŸæœ‰çš„æ ¸å¿ƒè®­ç»ƒé€»è¾‘
- æ‰€æœ‰æ–°å‚æ•°éƒ½æœ‰åˆç†çš„é»˜è®¤å€¼
- åŸæœ‰çš„è°ƒç”¨æ–¹å¼ä»ç„¶æœ‰æ•ˆ

### ä¾èµ–è¦æ±‚
- PyTorch >= 1.8.0 (æ”¯æŒæ··åˆç²¾åº¦è®­ç»ƒ)
- å…¶ä»–ä¾èµ–ä¿æŒä¸å˜

## ğŸ¯ ä½¿ç”¨å»ºè®®

1. **é¦–æ¬¡è®­ç»ƒ**: ä½¿ç”¨é»˜è®¤å‚æ•°å¼€å§‹ï¼Œè§‚å¯Ÿè®­ç»ƒæ•ˆæœ
2. **æ€§èƒ½è°ƒä¼˜**: æ ¹æ®éªŒè¯ç»“æœè°ƒæ•´å­¦ä¹ ç‡å’ŒæŸå¤±æƒé‡
3. **å†…å­˜ä¼˜åŒ–**: æ ¹æ®GPUå†…å­˜è°ƒæ•´æ‰¹æ¬¡å¤§å°å’Œç´¯ç§¯æ­¥æ•°
4. **å®éªŒç®¡ç†**: ä½¿ç”¨ä¸åŒçš„output_dirç®¡ç†å¤šä¸ªå®éªŒ
5. **ç›‘æ§è®­ç»ƒ**: ä½¿ç”¨TensorBoardå®æ—¶ç›‘æ§è®­ç»ƒè¿‡ç¨‹

## ğŸ“ æ€»ç»“

æœ¬æ¬¡ä¼˜åŒ–åœ¨ä¿æŒä»£ç å¯è¯»æ€§å’Œç»´æŠ¤æ€§çš„åŒæ—¶ï¼Œæ˜¾è‘—æå‡äº†è®­ç»ƒè„šæœ¬çš„åŠŸèƒ½æ€§å’Œæ€§èƒ½ã€‚ä¸»è¦æ”¹è¿›åŒ…æ‹¬ï¼š

- **æ›´çµæ´»çš„é…ç½®é€‰é¡¹**
- **æ›´ç¨³å®šçš„è®­ç»ƒè¿‡ç¨‹**
- **æ›´å¥½çš„ç›‘æ§å’Œè°ƒè¯•èƒ½åŠ›**
- **æ›´å¼ºçš„å®éªŒç®¡ç†åŠŸèƒ½**
- **æ›´é«˜çš„è®­ç»ƒæ•ˆç‡**

è¿™äº›ä¼˜åŒ–ä½¿å¾—è®­ç»ƒè„šæœ¬æ›´é€‚åˆå®é™…çš„ç ”ç©¶å’Œç”Ÿäº§ç¯å¢ƒä½¿ç”¨ã€‚